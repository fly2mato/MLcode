{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    def __init__(self, feature_i=None, threshold=None, value=None, child=None):\n",
    "        self.feature_i = feature_i\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.child = child    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, max_depth=float(\"inf\"), min_samples_split=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def fit(self, X, y):   \n",
    "        index = np.arange(X.shape[1])\n",
    "        self.dt = self._build_tree(X,y,0, index)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth, feature_index):\n",
    "        m,n = X[:,feature_index].shape\n",
    "        label_value = np.unique(y)\n",
    "        if len(label_value)==1 or len(feature_index)==0:\n",
    "            node = TreeNode(value=label_value[0])\n",
    "            return node\n",
    "        \n",
    "        '''\n",
    "        for k in label_value:\n",
    "            if sum(y==k)/m>0.95:\n",
    "                node = TreeNode(value=k)\n",
    "                return node\n",
    "        '''\n",
    "        \n",
    "        Gini_max = None\n",
    "        if m>self.min_samples_split and depth<=self.max_depth:\n",
    "            for i in feature_index:\n",
    "                feature_value = np.unique(X[:,i])\n",
    "                for j in feature_value:\n",
    "                    #index_true = X[:,i]==j\n",
    "                    #index_false = X[:,i]!=j\n",
    "                    index_true = X[:,i]>=j\n",
    "                    index_false = X[:,i]<j\n",
    "                    \n",
    "                    '''\n",
    "                    Gtrue = 1\n",
    "                    Gfalse = 1\n",
    "                    for k in label_value:\n",
    "                        Gtrue -= (sum(y[index_true]==k)/m)**2\n",
    "                        Gfalse -= (sum(y[index_false]==k)/m)**2    \n",
    "                    Gini = sum(index_true)/m*Gtrue + sum(index_false)/m*Gfalse\n",
    "                    \n",
    "                    \n",
    "                    '''\n",
    "                    ptrue = sum(index_true)/m\n",
    "                    pfalse = sum(index_false)/m\n",
    "                    Gtrue = 0\n",
    "                    Gfalse = 0\n",
    "                    Hda = 0\n",
    "                    Gini = 0\n",
    "                    for k in label_value:\n",
    "                        print(y[index_true]==k)\n",
    "                        p = sum(y[index_true]==k)/m\n",
    "                        if p>0: Gtrue += -ptrue*p*np.log2(p)\n",
    "                        p = sum(y[index_false]==k)/m\n",
    "                        if p>0: Gfalse += -pfalse*p*np.log2(p)\n",
    "                        if p>0: p = sum(y==k)/m\n",
    "                        Hda += -p*np.log2(p)\n",
    "                    \n",
    "                    if ptrue>0: Gini += -ptrue*np.log2(ptrue)\n",
    "                    if pfalse>0: Gini += -pfalse*np.log2(pfalse)\n",
    "                    Gini = - (Gtrue + Gfalse)\n",
    "                    Gini /= Hda\n",
    "                    #'''\n",
    "                    \n",
    "                    if Gini_max==None or Gini>Gini_max:\n",
    "                        Gini_max=Gini\n",
    "                        decision_feature_index = i\n",
    "                        decision_feature_value = j\n",
    "                        index_true_max = index_true.copy()\n",
    "                        index_false_max = index_false.copy()\n",
    "\n",
    "            next_index = feature_index!=decision_feature_index\n",
    "            node = TreeNode(feature_i=decision_feature_index, threshold=decision_feature_value)\n",
    "            \n",
    "            node.child = [self._build_tree(X[index_true_max, :], y[index_true_max], depth+1, next_index),\n",
    "                          self._build_tree(X[index_false_max,:], y[index_false_max],depth+1, next_index) \n",
    "                         ]\n",
    "            #node.child = [self._build_tree(X[index_true_max, :], y[index_true_max], depth+1),\n",
    "            #              self._build_tree(X[index_false_max,:], y[index_false_max],depth+1) \n",
    "            #             ]\n",
    "            return node\n",
    "        \n",
    "        value = label_value[np.argmax([sum(y==yi) for yi in label_value])]\n",
    "        node = TreeNode(value=value)\n",
    "        return node\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [self._predict(x) for x in X]\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        pt = self.dt\n",
    "        while pt.value==None :\n",
    "            if (x[pt.feature_i]>=pt.threshold):\n",
    "                pt = pt.child[0]\n",
    "            else:\n",
    "                pt = pt.child[1]\n",
    "        return pt.value\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangbo39/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:56: RuntimeWarning: divide by zero encountered in log2\n",
      "/home/zhangbo39/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-937ba3b9dc6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-227-4861d0a40a46>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-227-4861d0a40a46>\u001b[0m in \u001b[0;36m_build_tree\u001b[0;34m(self, X, y, depth, feature_index)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecision_feature_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecision_feature_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             node.child = [self._build_tree(X[index_true_max, :], y[index_true_max], depth+1, next_index),\n\u001b[0m\u001b[1;32m     75\u001b[0m                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_false_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_false_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                          ]\n",
      "\u001b[0;32m<ipython-input-227-4861d0a40a46>\u001b[0m in \u001b[0;36m_build_tree\u001b[0;34m(self, X, y, depth, feature_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mGini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGtrue\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mptrue\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_false\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "clf = DecisionTree()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f257769ceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print (\"Accuracy:\", accuracy)\n",
    "\n",
    "Plot().plot_in_2d(X_test, y_pred,\n",
    "        title=\"Decision Tree\",\n",
    "        accuracy=accuracy,\n",
    "legend_labels=data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "\n",
    "def calculate_entropy(y):\n",
    "    \"\"\" Calculate the entropy of label array y \"\"\"\n",
    "    log2 = lambda x: math.log(x) / math.log(2)\n",
    "    unique_labels = np.unique(y)\n",
    "    entropy = 0\n",
    "    for label in unique_labels:\n",
    "        count = len(y[y == label])\n",
    "        p = count / len(y)\n",
    "        entropy += -p * log2(p)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\" Returns the mean squared error between y_true and y_pred \"\"\"\n",
    "    mse = np.mean(np.power(y_true - y_pred, 2))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def calculate_variance(X):\n",
    "    \"\"\" Return the variance of the features in dataset X \"\"\"\n",
    "    mean = np.ones(np.shape(X)) * X.mean(0)\n",
    "    n_samples = np.shape(X)[0]\n",
    "    variance = (1 / n_samples) * np.diag((X - mean).T.dot(X - mean))\n",
    "    \n",
    "    return variance\n",
    "\n",
    "\n",
    "def calculate_std_dev(X):\n",
    "    \"\"\" Calculate the standard deviations of the features in dataset X \"\"\"\n",
    "    std_dev = np.sqrt(calculate_variance(X))\n",
    "    return std_dev\n",
    "\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\" Calculates the l2 distance between two vectors \"\"\"\n",
    "    distance = 0\n",
    "    # Squared distance between each coordinate\n",
    "    for i in range(len(x1)):\n",
    "        distance += pow((x1[i] - x2[i]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\" Compare y_true to y_pred and return the accuracy \"\"\"\n",
    "    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_covariance_matrix(X, Y=None):\n",
    "    \"\"\" Calculate the covariance matrix for the dataset X \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n_samples = np.shape(X)[0]\n",
    "    covariance_matrix = (1 / (n_samples-1)) * (X - X.mean(axis=0)).T.dot(Y - Y.mean(axis=0))\n",
    "\n",
    "    return np.array(covariance_matrix, dtype=float)\n",
    " \n",
    "\n",
    "def calculate_correlation_matrix(X, Y=None):\n",
    "    \"\"\" Calculate the correlation matrix for the dataset X \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n_samples = np.shape(X)[0]\n",
    "    covariance = (1 / n_samples) * (X - X.mean(0)).T.dot(Y - Y.mean(0))\n",
    "    std_dev_X = np.expand_dims(calculate_std_dev(X), 1)\n",
    "    std_dev_y = np.expand_dims(calculate_std_dev(Y), 1)\n",
    "    correlation_matrix = np.divide(covariance, std_dev_X.dot(std_dev_y.T))\n",
    "\n",
    "    return np.array(correlation_matrix, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "#from utils.data_operation import calculate_covariance_matrix\n",
    "#from utils.data_operation import calculate_correlation_matrix\n",
    "#from utils.data_manipulation import standardize\n",
    "\n",
    "bar_widgets = [\n",
    "    'Training: ', progressbar.Percentage(), ' ', progressbar.Bar(marker=\"-\", left=\"[\", right=\"]\"),\n",
    "    ' ', progressbar.ETA()\n",
    "]\n",
    "\n",
    "class Plot():\n",
    "    def __init__(self): \n",
    "        self.cmap = plt.get_cmap('viridis')\n",
    "\n",
    "    def _transform(self, X, dim):\n",
    "        covariance = calculate_covariance_matrix(X)\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n",
    "        # Sort eigenvalues and eigenvector by largest eigenvalues\n",
    "        idx = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues = eigenvalues[idx][:dim]\n",
    "        eigenvectors = np.atleast_1d(eigenvectors[:, idx])[:, :dim]\n",
    "        # Project the data onto principal components\n",
    "        X_transformed = X.dot(eigenvectors)\n",
    "\n",
    "        return X_transformed\n",
    "\n",
    "\n",
    "    def plot_regression(self, lines, title, axis_labels=None, mse=None, scatter=None, legend={\"type\": \"lines\", \"loc\": \"lower right\"}):\n",
    "        \n",
    "        if scatter:\n",
    "            scatter_plots = scatter_labels = []\n",
    "            for s in scatter:\n",
    "                scatter_plots += [plt.scatter(s[\"x\"], s[\"y\"], color=s[\"color\"], s=s[\"size\"])]\n",
    "                scatter_labels += [s[\"label\"]]\n",
    "            scatter_plots = tuple(scatter_plots)\n",
    "            scatter_labels = tuple(scatter_labels)\n",
    "\n",
    "        for l in lines:\n",
    "            li = plt.plot(l[\"x\"], l[\"y\"], color=s[\"color\"], linewidth=l[\"width\"], label=l[\"label\"])\n",
    "\n",
    "        if mse:\n",
    "            plt.suptitle(title)\n",
    "            plt.title(\"MSE: %.2f\" % mse, fontsize=10)\n",
    "        else:\n",
    "            plt.title(title)\n",
    "\n",
    "        if axis_labels:\n",
    "            plt.xlabel(axis_labels[\"x\"])\n",
    "            plt.ylabel(axis_labels[\"y\"])\n",
    "\n",
    "        if legend[\"type\"] == \"lines\":\n",
    "            plt.legend(loc=\"lower_left\")\n",
    "        elif legend[\"type\"] == \"scatter\" and scatter:\n",
    "            plt.legend(scatter_plots, scatter_labels, loc=legend[\"loc\"])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the dataset X and the corresponding labels y in 2D using PCA.\n",
    "    def plot_in_2d(self, X, y=None, title=None, accuracy=None, legend_labels=None):\n",
    "        X_transformed = self._transform(X, dim=2)\n",
    "        x1 = X_transformed[:, 0]\n",
    "        x2 = X_transformed[:, 1]\n",
    "        class_distr = []\n",
    "\n",
    "        y = np.array(y).astype(int)\n",
    "\n",
    "        colors = [self.cmap(i) for i in np.linspace(0, 1, len(np.unique(y)))]\n",
    "\n",
    "        # Plot the different class distributions\n",
    "        for i, l in enumerate(np.unique(y)):\n",
    "            _x1 = x1[y == l]\n",
    "            _x2 = x2[y == l]\n",
    "            _y = y[y == l]\n",
    "            class_distr.append(plt.scatter(_x1, _x2, color=colors[i]))\n",
    "\n",
    "        # Plot legend\n",
    "        if not legend_labels is None: \n",
    "            plt.legend(class_distr, legend_labels, loc=1)\n",
    "\n",
    "        # Plot title\n",
    "        if title:\n",
    "            if accuracy:\n",
    "                perc = 100 * accuracy\n",
    "                plt.suptitle(title)\n",
    "                plt.title(\"Accuracy: %.1f%%\" % perc, fontsize=10)\n",
    "            else:\n",
    "                plt.title(title)\n",
    "\n",
    "        # Axis labels\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Plot the dataset X and the corresponding labels y in 3D using PCA.\n",
    "    def plot_in_3d(self, X, y=None):\n",
    "        X_transformed = self._transform(X, dim=3)\n",
    "        x1 = X_transformed[:, 0]\n",
    "        x2 = X_transformed[:, 1]\n",
    "        x3 = X_transformed[:, 2]\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(x1, x2, x3, c=y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../mytest/DTdata.txt', header=None, sep=' ')\n",
    "y = data.values[:,0]\n",
    "X = data.values[:,1:]\n",
    "dt = DecisionTree(max_depth=5)\n",
    "dt.fit(X,y)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
