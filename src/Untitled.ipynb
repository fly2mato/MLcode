{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 785), (28000, 784))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import xgboost as xgb \n",
    "from sklearn.cross_validation import train_test_split \n",
    "\n",
    "#记录程序运行时间 \n",
    "import time \n",
    "start_time = time.time() \n",
    "\n",
    "#读入数据 \n",
    "train = pd.read_csv(\"/home/zhangbo39/Downloads/mnist_train.csv\") \n",
    "tests = pd.read_csv(\"/home/zhangbo39/Downloads/mnist_test.csv\") \n",
    "\n",
    "train.shape, tests.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangbo39/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/zhangbo39/anaconda3/lib/python3.6/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "train_xy, val = train_test_split(train, test_size=0.3)\n",
    "train_y = train_xy.label\n",
    "train_x = train_xy.drop(['label'], axis=1)\n",
    "val_y = val.label\n",
    "val_x = val.drop(['label'], axis=1)\n",
    "\n",
    "xgb_train = xgb.DMatrix(train_x, label=train_y)\n",
    "xgb_val = xgb.DMatrix(val_x, label=val_y)\n",
    "xgb_test = xgb.DMatrix(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={ 'booster':'gbtree', \n",
    "        'objective': 'multi:softmax', #多分类的问题 \n",
    "        'num_class':10, # 类别数，与 multisoftmax 并用 \n",
    "        #'eval_metric': 'auc',\n",
    "        'seed':1,  \n",
    "        'gamma':0.1, # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。 \n",
    "        'max_depth':12, # 构建树的深度，越大越容易过拟合 \n",
    "        'lambda':2, # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。 \n",
    "        'subsample':1, #0.7, # 随机采样训练样本 \n",
    "        'colsample_bytree':1, #0.7, # 生成树时进行的列采样 \n",
    "        'min_child_weight':1, #3, \n",
    "        # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言 \n",
    "        #，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。 \n",
    "        #这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "        'silent':0, #设置成1则没有运行信息输出，最好是设置为0. \n",
    "        'eta': 0.3, #0.007, # 如同学习率 \n",
    "        \n",
    "        'nthread':8#7 # cpu 线程数 #\n",
    "        \n",
    "       } \n",
    "\n",
    "\n",
    "plst = list(params.items()) \n",
    "num_rounds = 1000 # 迭代次数 \n",
    "watchlist = [(xgb_train, 'train'),(xgb_val, 'val')] #训练模型并保存 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.045816\tval-merror:0.10881\n",
      "Multiple eval metrics have been passed: 'val-merror' will be used for early stopping.\n",
      "\n",
      "Will train until val-merror hasn't improved in 100 rounds.\n",
      "[1]\ttrain-merror:0.025646\tval-merror:0.077857\n",
      "[2]\ttrain-merror:0.019354\tval-merror:0.066905\n",
      "[3]\ttrain-merror:0.01398\tval-merror:0.062063\n",
      "[4]\ttrain-merror:0.010272\tval-merror:0.057857\n",
      "[5]\ttrain-merror:0.008095\tval-merror:0.055635\n",
      "[6]\ttrain-merror:0.006599\tval-merror:0.053413\n",
      "[7]\ttrain-merror:0.00483\tval-merror:0.050873\n",
      "[8]\ttrain-merror:0.003299\tval-merror:0.048889\n",
      "[9]\ttrain-merror:0.002619\tval-merror:0.047619\n",
      "[10]\ttrain-merror:0.001803\tval-merror:0.046905\n",
      "[11]\ttrain-merror:0.001497\tval-merror:0.046587\n",
      "[12]\ttrain-merror:0.001122\tval-merror:0.044921\n",
      "[13]\ttrain-merror:0.000918\tval-merror:0.044683\n",
      "[14]\ttrain-merror:0.000612\tval-merror:0.043889\n",
      "[15]\ttrain-merror:0.000476\tval-merror:0.043571\n",
      "[16]\ttrain-merror:0.000374\tval-merror:0.043095\n",
      "[17]\ttrain-merror:0.000238\tval-merror:0.042381\n",
      "[18]\ttrain-merror:0.000136\tval-merror:0.041825\n",
      "[19]\ttrain-merror:3.4e-05\tval-merror:0.041587\n",
      "[20]\ttrain-merror:3.4e-05\tval-merror:0.041032\n",
      "[21]\ttrain-merror:0\tval-merror:0.039762\n",
      "[22]\ttrain-merror:0\tval-merror:0.039048\n",
      "[23]\ttrain-merror:0\tval-merror:0.038968\n",
      "[24]\ttrain-merror:0\tval-merror:0.03873\n",
      "[25]\ttrain-merror:0\tval-merror:0.038095\n",
      "[26]\ttrain-merror:0\tval-merror:0.037381\n",
      "[27]\ttrain-merror:0\tval-merror:0.036984\n",
      "[28]\ttrain-merror:0\tval-merror:0.036905\n",
      "[29]\ttrain-merror:0\tval-merror:0.036508\n",
      "[30]\ttrain-merror:0\tval-merror:0.036349\n",
      "[31]\ttrain-merror:0\tval-merror:0.035873\n",
      "[32]\ttrain-merror:0\tval-merror:0.035873\n",
      "[33]\ttrain-merror:0\tval-merror:0.035635\n",
      "[34]\ttrain-merror:0\tval-merror:0.035397\n",
      "[35]\ttrain-merror:0\tval-merror:0.034603\n",
      "[36]\ttrain-merror:0\tval-merror:0.034603\n",
      "[37]\ttrain-merror:0\tval-merror:0.034683\n",
      "[38]\ttrain-merror:0\tval-merror:0.034206\n",
      "[39]\ttrain-merror:0\tval-merror:0.034365\n",
      "[40]\ttrain-merror:0\tval-merror:0.03381\n",
      "[41]\ttrain-merror:0\tval-merror:0.03373\n",
      "[42]\ttrain-merror:0\tval-merror:0.033651\n",
      "[43]\ttrain-merror:0\tval-merror:0.033889\n",
      "[44]\ttrain-merror:0\tval-merror:0.03373\n",
      "[45]\ttrain-merror:0\tval-merror:0.033651\n",
      "[46]\ttrain-merror:0\tval-merror:0.033651\n",
      "[47]\ttrain-merror:0\tval-merror:0.03373\n",
      "[48]\ttrain-merror:0\tval-merror:0.03381\n",
      "[49]\ttrain-merror:0\tval-merror:0.033889\n",
      "[50]\ttrain-merror:0\tval-merror:0.033651\n",
      "[51]\ttrain-merror:0\tval-merror:0.033413\n",
      "[52]\ttrain-merror:0\tval-merror:0.033413\n",
      "[53]\ttrain-merror:0\tval-merror:0.033413\n",
      "[54]\ttrain-merror:0\tval-merror:0.033413\n",
      "[55]\ttrain-merror:0\tval-merror:0.033254\n",
      "[56]\ttrain-merror:0\tval-merror:0.033016\n",
      "[57]\ttrain-merror:0\tval-merror:0.032937\n",
      "[58]\ttrain-merror:0\tval-merror:0.033175\n",
      "[59]\ttrain-merror:0\tval-merror:0.033175\n",
      "[60]\ttrain-merror:0\tval-merror:0.033254\n",
      "[61]\ttrain-merror:0\tval-merror:0.033175\n",
      "[62]\ttrain-merror:0\tval-merror:0.033095\n",
      "[63]\ttrain-merror:0\tval-merror:0.033016\n",
      "[64]\ttrain-merror:0\tval-merror:0.033016\n",
      "[65]\ttrain-merror:0\tval-merror:0.033095\n",
      "[66]\ttrain-merror:0\tval-merror:0.033254\n",
      "[67]\ttrain-merror:0\tval-merror:0.033175\n",
      "[68]\ttrain-merror:0\tval-merror:0.033254\n",
      "[69]\ttrain-merror:0\tval-merror:0.033333\n",
      "[70]\ttrain-merror:0\tval-merror:0.033333\n",
      "[71]\ttrain-merror:0\tval-merror:0.033254\n",
      "[72]\ttrain-merror:0\tval-merror:0.033254\n",
      "[73]\ttrain-merror:0\tval-merror:0.033254\n",
      "[74]\ttrain-merror:0\tval-merror:0.033254\n",
      "[75]\ttrain-merror:0\tval-merror:0.033254\n",
      "[76]\ttrain-merror:0\tval-merror:0.033254\n",
      "[77]\ttrain-merror:0\tval-merror:0.033254\n",
      "[78]\ttrain-merror:0\tval-merror:0.033254\n",
      "[79]\ttrain-merror:0\tval-merror:0.033254\n",
      "[80]\ttrain-merror:0\tval-merror:0.033254\n",
      "[81]\ttrain-merror:0\tval-merror:0.033254\n",
      "[82]\ttrain-merror:0\tval-merror:0.033254\n",
      "[83]\ttrain-merror:0\tval-merror:0.033254\n",
      "[84]\ttrain-merror:0\tval-merror:0.033254\n",
      "[85]\ttrain-merror:0\tval-merror:0.033254\n",
      "[86]\ttrain-merror:0\tval-merror:0.033254\n",
      "[87]\ttrain-merror:0\tval-merror:0.033254\n",
      "[88]\ttrain-merror:0\tval-merror:0.033254\n",
      "[89]\ttrain-merror:0\tval-merror:0.033254\n",
      "[90]\ttrain-merror:0\tval-merror:0.033254\n",
      "[91]\ttrain-merror:0\tval-merror:0.033254\n",
      "[92]\ttrain-merror:0\tval-merror:0.033254\n",
      "[93]\ttrain-merror:0\tval-merror:0.033254\n",
      "[94]\ttrain-merror:0\tval-merror:0.033254\n",
      "[95]\ttrain-merror:0\tval-merror:0.033254\n",
      "[96]\ttrain-merror:0\tval-merror:0.033254\n",
      "[97]\ttrain-merror:0\tval-merror:0.033254\n",
      "[98]\ttrain-merror:0\tval-merror:0.033254\n",
      "[99]\ttrain-merror:0\tval-merror:0.033254\n",
      "[100]\ttrain-merror:0\tval-merror:0.033254\n",
      "[101]\ttrain-merror:0\tval-merror:0.033254\n",
      "[102]\ttrain-merror:0\tval-merror:0.033254\n",
      "[103]\ttrain-merror:0\tval-merror:0.033254\n",
      "[104]\ttrain-merror:0\tval-merror:0.033254\n",
      "[105]\ttrain-merror:0\tval-merror:0.033254\n",
      "[106]\ttrain-merror:0\tval-merror:0.033254\n",
      "[107]\ttrain-merror:0\tval-merror:0.033254\n",
      "[108]\ttrain-merror:0\tval-merror:0.033254\n",
      "[109]\ttrain-merror:0\tval-merror:0.033254\n",
      "[110]\ttrain-merror:0\tval-merror:0.033254\n",
      "[111]\ttrain-merror:0\tval-merror:0.033254\n",
      "[112]\ttrain-merror:0\tval-merror:0.033254\n",
      "[113]\ttrain-merror:0\tval-merror:0.033254\n",
      "[114]\ttrain-merror:0\tval-merror:0.033254\n",
      "[115]\ttrain-merror:0\tval-merror:0.033254\n",
      "[116]\ttrain-merror:0\tval-merror:0.033254\n",
      "[117]\ttrain-merror:0\tval-merror:0.033254\n",
      "[118]\ttrain-merror:0\tval-merror:0.033254\n",
      "[119]\ttrain-merror:0\tval-merror:0.033254\n",
      "[120]\ttrain-merror:0\tval-merror:0.033254\n",
      "[121]\ttrain-merror:0\tval-merror:0.033254\n",
      "[122]\ttrain-merror:0\tval-merror:0.033254\n",
      "[123]\ttrain-merror:0\tval-merror:0.033254\n",
      "[124]\ttrain-merror:0\tval-merror:0.033254\n",
      "[125]\ttrain-merror:0\tval-merror:0.033254\n",
      "[126]\ttrain-merror:0\tval-merror:0.033254\n",
      "[127]\ttrain-merror:0\tval-merror:0.033254\n",
      "[128]\ttrain-merror:0\tval-merror:0.033254\n",
      "[129]\ttrain-merror:0\tval-merror:0.033254\n",
      "[130]\ttrain-merror:0\tval-merror:0.033254\n",
      "[131]\ttrain-merror:0\tval-merror:0.033254\n",
      "[132]\ttrain-merror:0\tval-merror:0.033254\n",
      "[133]\ttrain-merror:0\tval-merror:0.033254\n",
      "[134]\ttrain-merror:0\tval-merror:0.033254\n",
      "[135]\ttrain-merror:0\tval-merror:0.033254\n",
      "[136]\ttrain-merror:0\tval-merror:0.033254\n",
      "[137]\ttrain-merror:0\tval-merror:0.033254\n",
      "[138]\ttrain-merror:0\tval-merror:0.033254\n",
      "[139]\ttrain-merror:0\tval-merror:0.033254\n",
      "[140]\ttrain-merror:0\tval-merror:0.033254\n",
      "[141]\ttrain-merror:0\tval-merror:0.033254\n",
      "[142]\ttrain-merror:0\tval-merror:0.033254\n",
      "[143]\ttrain-merror:0\tval-merror:0.033254\n",
      "[144]\ttrain-merror:0\tval-merror:0.033254\n",
      "[145]\ttrain-merror:0\tval-merror:0.033254\n",
      "[146]\ttrain-merror:0\tval-merror:0.033254\n",
      "[147]\ttrain-merror:0\tval-merror:0.033254\n",
      "[148]\ttrain-merror:0\tval-merror:0.033254\n",
      "[149]\ttrain-merror:0\tval-merror:0.033254\n",
      "[150]\ttrain-merror:0\tval-merror:0.033254\n",
      "[151]\ttrain-merror:0\tval-merror:0.033254\n",
      "[152]\ttrain-merror:0\tval-merror:0.033254\n",
      "[153]\ttrain-merror:0\tval-merror:0.033254\n",
      "[154]\ttrain-merror:0\tval-merror:0.033254\n",
      "[155]\ttrain-merror:0\tval-merror:0.033254\n",
      "[156]\ttrain-merror:0\tval-merror:0.033254\n",
      "[157]\ttrain-merror:0\tval-merror:0.033254\n",
      "Stopping. Best iteration:\n",
      "[57]\ttrain-merror:0\tval-merror:0.032937\n",
      "\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "b'[17:38:14] /workspace/dmlc-core/src/io/local_filesys.cc:209: Check failed: allow_null  LocalFileSystem::Open \"./model/xgb.model\": No such file or directory\\n\\nStack trace returned 10 entries:\\n[bt] (0) /home/zhangbo39/anaconda3/xgboost/libxgboost.so(dmlc::StackTrace(unsigned long)+0x47) [0x7f4359fedfc7]\\n[bt] (1) /home/zhangbo39/anaconda3/xgboost/libxgboost.so(dmlc::io::LocalFileSystem::Open(dmlc::io::URI const&, char const*, bool)+0x411) [0x7f435a191dd1]\\n[bt] (2) /home/zhangbo39/anaconda3/xgboost/libxgboost.so(dmlc::Stream::Create(char const*, char const*, bool)+0x3a) [0x7f435a13e6fa]\\n[bt] (3) /home/zhangbo39/anaconda3/xgboost/libxgboost.so(XGBoosterSaveModel+0x2b) [0x7f4359fe66eb]\\n[bt] (4) /home/zhangbo39/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f439b41aec0]\\n[bt] (5) /home/zhangbo39/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f439b41a87d]\\n[bt] (6) /home/zhangbo39/anaconda3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f439b62fdee]\\n[bt] (7) /home/zhangbo39/anaconda3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12825) [0x7f439b630825]\\n[bt] (8) /home/zhangbo39/anaconda3/bin/python(_PyObject_FastCallDict+0x8b) [0x562e4c1761bb]\\n[bt] (9) /home/zhangbo39/anaconda3/bin/python(+0x19cd3e) [0x562e4c203d3e]\\n\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-415d53dd87c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model = xgb.train(params, xgb_train, num_rounds, watchlist,early_stopping_rounds=100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/xgb.model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 用于存储训练出的模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best best_ntree_limit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \"\"\"\n\u001b[1;32m   1331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# assume file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterSaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fname must be a string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \"\"\"\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: b'[17:38:14] /workspace/dmlc-core/src/io/local_filesys.cc:209: Check failed: allow_null  LocalFileSystem::Open \"./model/xgb.model\": No such file or directory\\n\\nStack trace returned 10 entries:\\n[bt] (0) /home/zhangbo39/anaconda3/xgboost/libxgboost.so(dmlc::StackTrace(unsigned long)+0x47) [0x7f4359fedfc7]\\n[bt] (1) /home/zhangbo39/anaconda3/xgboost/libxgboost.so(dmlc::io::LocalFileSystem::Open(dmlc::io::URI const&, char const*, bool)+0x411) [0x7f435a191dd1]\\n[bt] (2) /home/zhangbo39/anaconda3/xgboost/libxgboost.so(dmlc::Stream::Create(char const*, char const*, bool)+0x3a) [0x7f435a13e6fa]\\n[bt] (3) /home/zhangbo39/anaconda3/xgboost/libxgboost.so(XGBoosterSaveModel+0x2b) [0x7f4359fe66eb]\\n[bt] (4) /home/zhangbo39/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f439b41aec0]\\n[bt] (5) /home/zhangbo39/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f439b41a87d]\\n[bt] (6) /home/zhangbo39/anaconda3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f439b62fdee]\\n[bt] (7) /home/zhangbo39/anaconda3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12825) [0x7f439b630825]\\n[bt] (8) /home/zhangbo39/anaconda3/bin/python(_PyObject_FastCallDict+0x8b) [0x562e4c1761bb]\\n[bt] (9) /home/zhangbo39/anaconda3/bin/python(+0x19cd3e) [0x562e4c203d3e]\\n\\n'"
     ]
    }
   ],
   "source": [
    "#early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练 \n",
    "model = xgb.train(plst, xgb_train, num_rounds, watchlist,early_stopping_rounds=100) \n",
    "#model = xgb.train(params, xgb_train, num_rounds, watchlist,early_stopping_rounds=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best best_ntree_limit 58\n"
     ]
    }
   ],
   "source": [
    "model.save_model('./xgb.model') # 用于存储训练出的模型 \n",
    "print(\"best best_ntree_limit\",model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgb_test,ntree_limit=model.best_ntree_limit) \n",
    "np.savetxt('xgb_submission.csv',np.c_[range(1,len(tests)+1),preds],delimiter=',',header='ImageId,Label',comments='',fmt='%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.078401\tval-merror:0.119365\n",
      "Multiple eval metrics have been passed: 'val-merror' will be used for early stopping.\n",
      "\n",
      "Will train until val-merror hasn't improved in 100 rounds.\n",
      "[1]\ttrain-merror:0.063878\tval-merror:0.098333\n",
      "[2]\ttrain-merror:0.050034\tval-merror:0.086429\n",
      "[3]\ttrain-merror:0.044422\tval-merror:0.078413\n",
      "[4]\ttrain-merror:0.040442\tval-merror:0.072937\n",
      "[5]\ttrain-merror:0.03932\tval-merror:0.070317\n",
      "[6]\ttrain-merror:0.036361\tval-merror:0.068968\n",
      "[7]\ttrain-merror:0.034116\tval-merror:0.067222\n",
      "[8]\ttrain-merror:0.032143\tval-merror:0.064841\n",
      "[9]\ttrain-merror:0.030578\tval-merror:0.064365\n",
      "[10]\ttrain-merror:0.028503\tval-merror:0.064048\n",
      "[11]\ttrain-merror:0.026633\tval-merror:0.062222\n",
      "[12]\ttrain-merror:0.025408\tval-merror:0.061349\n",
      "[13]\ttrain-merror:0.024082\tval-merror:0.060794\n",
      "[14]\ttrain-merror:0.022789\tval-merror:0.059683\n",
      "[15]\ttrain-merror:0.021531\tval-merror:0.058413\n",
      "[16]\ttrain-merror:0.020238\tval-merror:0.058254\n",
      "[17]\ttrain-merror:0.018946\tval-merror:0.057698\n",
      "[18]\ttrain-merror:0.018027\tval-merror:0.057063\n",
      "[19]\ttrain-merror:0.016735\tval-merror:0.056349\n",
      "[20]\ttrain-merror:0.016122\tval-merror:0.055397\n",
      "[21]\ttrain-merror:0.015102\tval-merror:0.054524\n",
      "[22]\ttrain-merror:0.014184\tval-merror:0.053968\n",
      "[23]\ttrain-merror:0.013333\tval-merror:0.053016\n",
      "[24]\ttrain-merror:0.012347\tval-merror:0.052778\n",
      "[25]\ttrain-merror:0.011395\tval-merror:0.052143\n",
      "[26]\ttrain-merror:0.01085\tval-merror:0.051984\n",
      "[27]\ttrain-merror:0.010136\tval-merror:0.051429\n",
      "[28]\ttrain-merror:0.00949\tval-merror:0.050794\n",
      "[29]\ttrain-merror:0.008912\tval-merror:0.050238\n",
      "[30]\ttrain-merror:0.008299\tval-merror:0.049524\n",
      "[31]\ttrain-merror:0.007857\tval-merror:0.049127\n",
      "[32]\ttrain-merror:0.007347\tval-merror:0.048413\n",
      "[33]\ttrain-merror:0.006735\tval-merror:0.048254\n",
      "[34]\ttrain-merror:0.006327\tval-merror:0.047698\n",
      "[35]\ttrain-merror:0.005748\tval-merror:0.047381\n",
      "[36]\ttrain-merror:0.005204\tval-merror:0.047063\n",
      "[37]\ttrain-merror:0.004966\tval-merror:0.046508\n",
      "[38]\ttrain-merror:0.004558\tval-merror:0.04627\n",
      "[39]\ttrain-merror:0.004218\tval-merror:0.046111\n",
      "[40]\ttrain-merror:0.004014\tval-merror:0.045\n",
      "[41]\ttrain-merror:0.003673\tval-merror:0.045079\n",
      "[42]\ttrain-merror:0.003401\tval-merror:0.044603\n",
      "[43]\ttrain-merror:0.003061\tval-merror:0.044286\n",
      "[44]\ttrain-merror:0.003027\tval-merror:0.043413\n",
      "[45]\ttrain-merror:0.002653\tval-merror:0.043095\n",
      "[46]\ttrain-merror:0.002517\tval-merror:0.042937\n",
      "[47]\ttrain-merror:0.002279\tval-merror:0.04254\n",
      "[48]\ttrain-merror:0.002041\tval-merror:0.042143\n",
      "[49]\ttrain-merror:0.001905\tval-merror:0.041825\n",
      "[50]\ttrain-merror:0.001871\tval-merror:0.041667\n",
      "[51]\ttrain-merror:0.001769\tval-merror:0.041905\n",
      "[52]\ttrain-merror:0.001599\tval-merror:0.041508\n",
      "[53]\ttrain-merror:0.001463\tval-merror:0.041746\n",
      "[54]\ttrain-merror:0.001293\tval-merror:0.041032\n",
      "[55]\ttrain-merror:0.001259\tval-merror:0.040952\n",
      "[56]\ttrain-merror:0.001224\tval-merror:0.040476\n",
      "[57]\ttrain-merror:0.00119\tval-merror:0.040238\n",
      "[58]\ttrain-merror:0.001122\tval-merror:0.040159\n",
      "[59]\ttrain-merror:0.000986\tval-merror:0.040238\n",
      "[60]\ttrain-merror:0.000918\tval-merror:0.039762\n",
      "[61]\ttrain-merror:0.00085\tval-merror:0.039524\n",
      "[62]\ttrain-merror:0.00085\tval-merror:0.039603\n",
      "[63]\ttrain-merror:0.00085\tval-merror:0.039365\n",
      "[64]\ttrain-merror:0.000782\tval-merror:0.039286\n",
      "[65]\ttrain-merror:0.000714\tval-merror:0.039365\n",
      "[66]\ttrain-merror:0.000612\tval-merror:0.039365\n",
      "[67]\ttrain-merror:0.000544\tval-merror:0.039444\n",
      "[68]\ttrain-merror:0.000544\tval-merror:0.039286\n",
      "[69]\ttrain-merror:0.00051\tval-merror:0.039206\n",
      "[70]\ttrain-merror:0.000442\tval-merror:0.03873\n",
      "[71]\ttrain-merror:0.000442\tval-merror:0.038651\n",
      "[72]\ttrain-merror:0.000374\tval-merror:0.038413\n",
      "[73]\ttrain-merror:0.000306\tval-merror:0.038413\n",
      "[74]\ttrain-merror:0.000306\tval-merror:0.037937\n",
      "[75]\ttrain-merror:0.000238\tval-merror:0.03754\n",
      "[76]\ttrain-merror:0.000136\tval-merror:0.037143\n",
      "[77]\ttrain-merror:0.000136\tval-merror:0.037302\n",
      "[78]\ttrain-merror:0.000102\tval-merror:0.037063\n",
      "[79]\ttrain-merror:6.8e-05\tval-merror:0.036905\n",
      "[80]\ttrain-merror:6.8e-05\tval-merror:0.036587\n",
      "[81]\ttrain-merror:3.4e-05\tval-merror:0.036587\n",
      "[82]\ttrain-merror:3.4e-05\tval-merror:0.036429\n",
      "[83]\ttrain-merror:3.4e-05\tval-merror:0.036508\n",
      "[84]\ttrain-merror:3.4e-05\tval-merror:0.036349\n",
      "[85]\ttrain-merror:3.4e-05\tval-merror:0.036508\n",
      "[86]\ttrain-merror:3.4e-05\tval-merror:0.036429\n",
      "[87]\ttrain-merror:3.4e-05\tval-merror:0.036349\n",
      "[88]\ttrain-merror:3.4e-05\tval-merror:0.036032\n",
      "[89]\ttrain-merror:3.4e-05\tval-merror:0.035952\n",
      "[90]\ttrain-merror:3.4e-05\tval-merror:0.035794\n",
      "[91]\ttrain-merror:3.4e-05\tval-merror:0.035794\n",
      "[92]\ttrain-merror:3.4e-05\tval-merror:0.035714\n",
      "[93]\ttrain-merror:3.4e-05\tval-merror:0.035714\n",
      "[94]\ttrain-merror:0\tval-merror:0.035476\n",
      "[95]\ttrain-merror:0\tval-merror:0.035397\n",
      "[96]\ttrain-merror:0\tval-merror:0.035317\n",
      "[97]\ttrain-merror:0\tval-merror:0.035238\n",
      "[98]\ttrain-merror:0\tval-merror:0.035079\n",
      "[99]\ttrain-merror:0\tval-merror:0.034841\n",
      "[100]\ttrain-merror:0\tval-merror:0.034683\n",
      "[101]\ttrain-merror:0\tval-merror:0.034683\n",
      "[102]\ttrain-merror:0\tval-merror:0.034603\n",
      "[103]\ttrain-merror:0\tval-merror:0.034683\n",
      "[104]\ttrain-merror:0\tval-merror:0.034444\n",
      "[105]\ttrain-merror:0\tval-merror:0.034286\n",
      "[106]\ttrain-merror:0\tval-merror:0.033889\n",
      "[107]\ttrain-merror:0\tval-merror:0.03373\n",
      "[108]\ttrain-merror:0\tval-merror:0.033889\n",
      "[109]\ttrain-merror:0\tval-merror:0.03381\n",
      "[110]\ttrain-merror:0\tval-merror:0.03373\n",
      "[111]\ttrain-merror:0\tval-merror:0.033651\n",
      "[112]\ttrain-merror:0\tval-merror:0.03373\n",
      "[113]\ttrain-merror:0\tval-merror:0.033651\n",
      "[114]\ttrain-merror:0\tval-merror:0.033492\n",
      "[115]\ttrain-merror:0\tval-merror:0.033413\n",
      "[116]\ttrain-merror:0\tval-merror:0.033333\n",
      "[117]\ttrain-merror:0\tval-merror:0.033175\n",
      "[118]\ttrain-merror:0\tval-merror:0.033254\n",
      "[119]\ttrain-merror:0\tval-merror:0.033175\n",
      "[120]\ttrain-merror:0\tval-merror:0.033095\n",
      "[121]\ttrain-merror:0\tval-merror:0.033095\n",
      "[122]\ttrain-merror:0\tval-merror:0.033016\n",
      "[123]\ttrain-merror:0\tval-merror:0.032937\n",
      "[124]\ttrain-merror:0\tval-merror:0.032937\n",
      "[125]\ttrain-merror:0\tval-merror:0.032937\n",
      "[126]\ttrain-merror:0\tval-merror:0.033016\n",
      "[127]\ttrain-merror:0\tval-merror:0.032857\n",
      "[128]\ttrain-merror:0\tval-merror:0.032937\n",
      "[129]\ttrain-merror:0\tval-merror:0.032937\n",
      "[130]\ttrain-merror:0\tval-merror:0.033095\n",
      "[131]\ttrain-merror:0\tval-merror:0.032778\n",
      "[132]\ttrain-merror:0\tval-merror:0.032698\n",
      "[133]\ttrain-merror:0\tval-merror:0.032778\n",
      "[134]\ttrain-merror:0\tval-merror:0.032778\n",
      "[135]\ttrain-merror:0\tval-merror:0.032698\n",
      "[136]\ttrain-merror:0\tval-merror:0.032698\n",
      "[137]\ttrain-merror:0\tval-merror:0.032778\n",
      "[138]\ttrain-merror:0\tval-merror:0.032619\n",
      "[139]\ttrain-merror:0\tval-merror:0.03246\n",
      "[140]\ttrain-merror:0\tval-merror:0.032619\n",
      "[141]\ttrain-merror:0\tval-merror:0.032698\n",
      "[142]\ttrain-merror:0\tval-merror:0.032619\n",
      "[143]\ttrain-merror:0\tval-merror:0.03246\n",
      "[144]\ttrain-merror:0\tval-merror:0.03246\n",
      "[145]\ttrain-merror:0\tval-merror:0.032381\n",
      "[146]\ttrain-merror:0\tval-merror:0.032143\n",
      "[147]\ttrain-merror:0\tval-merror:0.032302\n",
      "[148]\ttrain-merror:0\tval-merror:0.032143\n",
      "[149]\ttrain-merror:0\tval-merror:0.032143\n",
      "[150]\ttrain-merror:0\tval-merror:0.032143\n",
      "[151]\ttrain-merror:0\tval-merror:0.032143\n",
      "[152]\ttrain-merror:0\tval-merror:0.032063\n",
      "[153]\ttrain-merror:0\tval-merror:0.032222\n",
      "[154]\ttrain-merror:0\tval-merror:0.032143\n",
      "[155]\ttrain-merror:0\tval-merror:0.032063\n",
      "[156]\ttrain-merror:0\tval-merror:0.031984\n",
      "[157]\ttrain-merror:0\tval-merror:0.032143\n",
      "[158]\ttrain-merror:0\tval-merror:0.032063\n",
      "[159]\ttrain-merror:0\tval-merror:0.032063\n",
      "[160]\ttrain-merror:0\tval-merror:0.032063\n",
      "[161]\ttrain-merror:0\tval-merror:0.031905\n",
      "[162]\ttrain-merror:0\tval-merror:0.031905\n",
      "[163]\ttrain-merror:0\tval-merror:0.031746\n",
      "[164]\ttrain-merror:0\tval-merror:0.031825\n",
      "[165]\ttrain-merror:0\tval-merror:0.031825\n",
      "[166]\ttrain-merror:0\tval-merror:0.031746\n",
      "[167]\ttrain-merror:0\tval-merror:0.031746\n",
      "[168]\ttrain-merror:0\tval-merror:0.031667\n",
      "[169]\ttrain-merror:0\tval-merror:0.031746\n",
      "[170]\ttrain-merror:0\tval-merror:0.031587\n",
      "[171]\ttrain-merror:0\tval-merror:0.031746\n",
      "[172]\ttrain-merror:0\tval-merror:0.031667\n",
      "[173]\ttrain-merror:0\tval-merror:0.031587\n",
      "[174]\ttrain-merror:0\tval-merror:0.031587\n",
      "[175]\ttrain-merror:0\tval-merror:0.031429\n",
      "[176]\ttrain-merror:0\tval-merror:0.031508\n",
      "[177]\ttrain-merror:0\tval-merror:0.031508\n",
      "[178]\ttrain-merror:0\tval-merror:0.031508\n",
      "[179]\ttrain-merror:0\tval-merror:0.031429\n",
      "[180]\ttrain-merror:0\tval-merror:0.031429\n",
      "[181]\ttrain-merror:0\tval-merror:0.031508\n",
      "[182]\ttrain-merror:0\tval-merror:0.031349\n",
      "[183]\ttrain-merror:0\tval-merror:0.031349\n",
      "[184]\ttrain-merror:0\tval-merror:0.031349\n",
      "[185]\ttrain-merror:0\tval-merror:0.031429\n",
      "[186]\ttrain-merror:0\tval-merror:0.031349\n",
      "[187]\ttrain-merror:0\tval-merror:0.031349\n",
      "[188]\ttrain-merror:0\tval-merror:0.031349\n",
      "[189]\ttrain-merror:0\tval-merror:0.031349\n",
      "[190]\ttrain-merror:0\tval-merror:0.031349\n",
      "[191]\ttrain-merror:0\tval-merror:0.031349\n",
      "[192]\ttrain-merror:0\tval-merror:0.03127\n",
      "[193]\ttrain-merror:0\tval-merror:0.03127\n",
      "[194]\ttrain-merror:0\tval-merror:0.031349\n",
      "[195]\ttrain-merror:0\tval-merror:0.03119\n",
      "[196]\ttrain-merror:0\tval-merror:0.03119\n",
      "[197]\ttrain-merror:0\tval-merror:0.03119\n",
      "[198]\ttrain-merror:0\tval-merror:0.03119\n",
      "[199]\ttrain-merror:0\tval-merror:0.03119\n",
      "[200]\ttrain-merror:0\tval-merror:0.03119\n",
      "[201]\ttrain-merror:0\tval-merror:0.03119\n",
      "[202]\ttrain-merror:0\tval-merror:0.031111\n",
      "[203]\ttrain-merror:0\tval-merror:0.031111\n",
      "[204]\ttrain-merror:0\tval-merror:0.03119\n",
      "[205]\ttrain-merror:0\tval-merror:0.03119\n",
      "[206]\ttrain-merror:0\tval-merror:0.031111\n",
      "[207]\ttrain-merror:0\tval-merror:0.031111\n",
      "[208]\ttrain-merror:0\tval-merror:0.031111\n",
      "[209]\ttrain-merror:0\tval-merror:0.031111\n",
      "[210]\ttrain-merror:0\tval-merror:0.031111\n",
      "[211]\ttrain-merror:0\tval-merror:0.031111\n",
      "[212]\ttrain-merror:0\tval-merror:0.03119\n",
      "[213]\ttrain-merror:0\tval-merror:0.03119\n",
      "[214]\ttrain-merror:0\tval-merror:0.03119\n",
      "[215]\ttrain-merror:0\tval-merror:0.03119\n",
      "[216]\ttrain-merror:0\tval-merror:0.03119\n",
      "[217]\ttrain-merror:0\tval-merror:0.03119\n",
      "[218]\ttrain-merror:0\tval-merror:0.03119\n",
      "[219]\ttrain-merror:0\tval-merror:0.03119\n",
      "[220]\ttrain-merror:0\tval-merror:0.031111\n",
      "[221]\ttrain-merror:0\tval-merror:0.031111\n",
      "[222]\ttrain-merror:0\tval-merror:0.031111\n",
      "[223]\ttrain-merror:0\tval-merror:0.031111\n",
      "[224]\ttrain-merror:0\tval-merror:0.031111\n",
      "[225]\ttrain-merror:0\tval-merror:0.031111\n",
      "[226]\ttrain-merror:0\tval-merror:0.031111\n",
      "[227]\ttrain-merror:0\tval-merror:0.031111\n",
      "[228]\ttrain-merror:0\tval-merror:0.031111\n",
      "[229]\ttrain-merror:0\tval-merror:0.031111\n",
      "[230]\ttrain-merror:0\tval-merror:0.031111\n",
      "[231]\ttrain-merror:0\tval-merror:0.031111\n",
      "[232]\ttrain-merror:0\tval-merror:0.03119\n",
      "[233]\ttrain-merror:0\tval-merror:0.031111\n",
      "[234]\ttrain-merror:0\tval-merror:0.031111\n",
      "[235]\ttrain-merror:0\tval-merror:0.031111\n",
      "[236]\ttrain-merror:0\tval-merror:0.031111\n",
      "[237]\ttrain-merror:0\tval-merror:0.03119\n",
      "[238]\ttrain-merror:0\tval-merror:0.03119\n",
      "[239]\ttrain-merror:0\tval-merror:0.03119\n",
      "[240]\ttrain-merror:0\tval-merror:0.03119\n",
      "[241]\ttrain-merror:0\tval-merror:0.031032\n",
      "[242]\ttrain-merror:0\tval-merror:0.03119\n",
      "[243]\ttrain-merror:0\tval-merror:0.031111\n",
      "[244]\ttrain-merror:0\tval-merror:0.031111\n",
      "[245]\ttrain-merror:0\tval-merror:0.031111\n",
      "[246]\ttrain-merror:0\tval-merror:0.031111\n",
      "[247]\ttrain-merror:0\tval-merror:0.031111\n",
      "[248]\ttrain-merror:0\tval-merror:0.031111\n",
      "[249]\ttrain-merror:0\tval-merror:0.031111\n",
      "[250]\ttrain-merror:0\tval-merror:0.031111\n",
      "[251]\ttrain-merror:0\tval-merror:0.031111\n",
      "[252]\ttrain-merror:0\tval-merror:0.031111\n",
      "[253]\ttrain-merror:0\tval-merror:0.031111\n",
      "[254]\ttrain-merror:0\tval-merror:0.031111\n",
      "[255]\ttrain-merror:0\tval-merror:0.031111\n",
      "[256]\ttrain-merror:0\tval-merror:0.031111\n",
      "[257]\ttrain-merror:0\tval-merror:0.031111\n",
      "[258]\ttrain-merror:0\tval-merror:0.031111\n",
      "[259]\ttrain-merror:0\tval-merror:0.031032\n",
      "[260]\ttrain-merror:0\tval-merror:0.030952\n",
      "[261]\ttrain-merror:0\tval-merror:0.030952\n",
      "[262]\ttrain-merror:0\tval-merror:0.030952\n",
      "[263]\ttrain-merror:0\tval-merror:0.030952\n",
      "[264]\ttrain-merror:0\tval-merror:0.030952\n",
      "[265]\ttrain-merror:0\tval-merror:0.030952\n",
      "[266]\ttrain-merror:0\tval-merror:0.030952\n",
      "[267]\ttrain-merror:0\tval-merror:0.030952\n",
      "[268]\ttrain-merror:0\tval-merror:0.030952\n",
      "[269]\ttrain-merror:0\tval-merror:0.030952\n",
      "[270]\ttrain-merror:0\tval-merror:0.030952\n",
      "[271]\ttrain-merror:0\tval-merror:0.031032\n",
      "[272]\ttrain-merror:0\tval-merror:0.031032\n",
      "[273]\ttrain-merror:0\tval-merror:0.031032\n",
      "[274]\ttrain-merror:0\tval-merror:0.031032\n",
      "[275]\ttrain-merror:0\tval-merror:0.031032\n",
      "[276]\ttrain-merror:0\tval-merror:0.031032\n",
      "[277]\ttrain-merror:0\tval-merror:0.031032\n",
      "[278]\ttrain-merror:0\tval-merror:0.031032\n",
      "[279]\ttrain-merror:0\tval-merror:0.031032\n",
      "[280]\ttrain-merror:0\tval-merror:0.031032\n",
      "[281]\ttrain-merror:0\tval-merror:0.031032\n",
      "[282]\ttrain-merror:0\tval-merror:0.031032\n",
      "[283]\ttrain-merror:0\tval-merror:0.031032\n",
      "[284]\ttrain-merror:0\tval-merror:0.031032\n",
      "[285]\ttrain-merror:0\tval-merror:0.031032\n",
      "[286]\ttrain-merror:0\tval-merror:0.031032\n",
      "[287]\ttrain-merror:0\tval-merror:0.031032\n",
      "[288]\ttrain-merror:0\tval-merror:0.031032\n",
      "[289]\ttrain-merror:0\tval-merror:0.031032\n",
      "[290]\ttrain-merror:0\tval-merror:0.031032\n",
      "[291]\ttrain-merror:0\tval-merror:0.031032\n",
      "[292]\ttrain-merror:0\tval-merror:0.031111\n",
      "[293]\ttrain-merror:0\tval-merror:0.031111\n",
      "[294]\ttrain-merror:0\tval-merror:0.031111\n",
      "[295]\ttrain-merror:0\tval-merror:0.031111\n",
      "[296]\ttrain-merror:0\tval-merror:0.031111\n",
      "[297]\ttrain-merror:0\tval-merror:0.031111\n",
      "[298]\ttrain-merror:0\tval-merror:0.031111\n",
      "[299]\ttrain-merror:0\tval-merror:0.031111\n",
      "[300]\ttrain-merror:0\tval-merror:0.031111\n",
      "[301]\ttrain-merror:0\tval-merror:0.031111\n",
      "[302]\ttrain-merror:0\tval-merror:0.031111\n",
      "[303]\ttrain-merror:0\tval-merror:0.031111\n",
      "[304]\ttrain-merror:0\tval-merror:0.031111\n",
      "[305]\ttrain-merror:0\tval-merror:0.031111\n",
      "[306]\ttrain-merror:0\tval-merror:0.031111\n",
      "[307]\ttrain-merror:0\tval-merror:0.031111\n",
      "[308]\ttrain-merror:0\tval-merror:0.031111\n",
      "[309]\ttrain-merror:0\tval-merror:0.031111\n",
      "[310]\ttrain-merror:0\tval-merror:0.031111\n",
      "[311]\ttrain-merror:0\tval-merror:0.031111\n",
      "[312]\ttrain-merror:0\tval-merror:0.031111\n",
      "[313]\ttrain-merror:0\tval-merror:0.031111\n",
      "[314]\ttrain-merror:0\tval-merror:0.031111\n",
      "[315]\ttrain-merror:0\tval-merror:0.031111\n",
      "[316]\ttrain-merror:0\tval-merror:0.031111\n",
      "[317]\ttrain-merror:0\tval-merror:0.031111\n",
      "[318]\ttrain-merror:0\tval-merror:0.031111\n",
      "[319]\ttrain-merror:0\tval-merror:0.031111\n",
      "[320]\ttrain-merror:0\tval-merror:0.031111\n",
      "[321]\ttrain-merror:0\tval-merror:0.031111\n",
      "[322]\ttrain-merror:0\tval-merror:0.031111\n",
      "[323]\ttrain-merror:0\tval-merror:0.031111\n",
      "[324]\ttrain-merror:0\tval-merror:0.031111\n",
      "[325]\ttrain-merror:0\tval-merror:0.031111\n",
      "[326]\ttrain-merror:0\tval-merror:0.031111\n",
      "[327]\ttrain-merror:0\tval-merror:0.031111\n",
      "[328]\ttrain-merror:0\tval-merror:0.031111\n",
      "[329]\ttrain-merror:0\tval-merror:0.031111\n",
      "[330]\ttrain-merror:0\tval-merror:0.031111\n",
      "[331]\ttrain-merror:0\tval-merror:0.031111\n",
      "[332]\ttrain-merror:0\tval-merror:0.031111\n",
      "[333]\ttrain-merror:0\tval-merror:0.031111\n",
      "[334]\ttrain-merror:0\tval-merror:0.031111\n",
      "[335]\ttrain-merror:0\tval-merror:0.031111\n",
      "[336]\ttrain-merror:0\tval-merror:0.031111\n",
      "[337]\ttrain-merror:0\tval-merror:0.031111\n",
      "[338]\ttrain-merror:0\tval-merror:0.031111\n",
      "[339]\ttrain-merror:0\tval-merror:0.031111\n",
      "[340]\ttrain-merror:0\tval-merror:0.031111\n",
      "[341]\ttrain-merror:0\tval-merror:0.031111\n",
      "[342]\ttrain-merror:0\tval-merror:0.031111\n",
      "[343]\ttrain-merror:0\tval-merror:0.031111\n",
      "[344]\ttrain-merror:0\tval-merror:0.031111\n",
      "[345]\ttrain-merror:0\tval-merror:0.031111\n",
      "[346]\ttrain-merror:0\tval-merror:0.031111\n",
      "[347]\ttrain-merror:0\tval-merror:0.031111\n",
      "[348]\ttrain-merror:0\tval-merror:0.031111\n",
      "[349]\ttrain-merror:0\tval-merror:0.031111\n",
      "[350]\ttrain-merror:0\tval-merror:0.031111\n",
      "[351]\ttrain-merror:0\tval-merror:0.031111\n",
      "[352]\ttrain-merror:0\tval-merror:0.031111\n",
      "[353]\ttrain-merror:0\tval-merror:0.031111\n",
      "[354]\ttrain-merror:0\tval-merror:0.031111\n",
      "[355]\ttrain-merror:0\tval-merror:0.031111\n",
      "[356]\ttrain-merror:0\tval-merror:0.031111\n",
      "[357]\ttrain-merror:0\tval-merror:0.031111\n",
      "[358]\ttrain-merror:0\tval-merror:0.031111\n",
      "[359]\ttrain-merror:0\tval-merror:0.031111\n",
      "[360]\ttrain-merror:0\tval-merror:0.031111\n",
      "Stopping. Best iteration:\n",
      "[260]\ttrain-merror:0\tval-merror:0.030952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params={ 'booster':'gbtree', \n",
    "        'objective': 'multi:softmax', #多分类的问题 \n",
    "        'num_class':10, # 类别数，与 multisoftmax 并用 \n",
    "        #'eval_metric': 'auc',\n",
    "        'seed':1,  \n",
    "        'gamma':0.1, # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。 \n",
    "        'max_depth':8, # 构建树的深度，越大越容易过拟合 \n",
    "        'lambda':2, # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。 \n",
    "        'subsample':1, #0.7, # 随机采样训练样本 \n",
    "        'colsample_bytree':1, #0.7, # 生成树时进行的列采样 \n",
    "        'min_child_weight':1, #3, \n",
    "        # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言 \n",
    "        #，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。 \n",
    "        #这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "        'silent':0, #设置成1则没有运行信息输出，最好是设置为0. \n",
    "        'eta': 0.1, #0.007, # 如同学习率 \n",
    "        \n",
    "        'nthread':7 # cpu 线程数 #\n",
    "        \n",
    "       } \n",
    "\n",
    "num_rounds = 5000 # 迭代次数 \n",
    "watchlist = [(xgb_train, 'train'),(xgb_val, 'val')] #训练模型并保存 \n",
    "model = xgb.train(params, xgb_train, num_rounds, watchlist,early_stopping_rounds=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
